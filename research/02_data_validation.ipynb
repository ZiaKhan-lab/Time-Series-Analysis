{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_data=pd.read_csv('artifacts/data_ingestion/Dataset/train_FD001.txt', sep=\" \", header=None)\n",
    "jet_data.columns = [\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\"\n",
    "                    ,\"sensor6\",\"sensor7\",\"sensor8\",\"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\"\n",
    "                    ,\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "                    ,\"sensor20\",\"sensor21\",\"sensor22\",\"sensor23\"]\n",
    "\n",
    "jet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    root_dir: Path\n",
    "    STATUS_FILE: str\n",
    "    unzip_data_dir: Path\n",
    "    all_schema: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.TimeSeriesProject .constants import *\n",
    "from src.TimeSeriesProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "        schema = self.schema.COLUMNS\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_validation_config = DataValidationConfig(\n",
    "        root_dir=config.root_dir,\n",
    "        STATUS_FILE=config.STATUS_FILE,\n",
    "        unzip_data_dir = config.unzip_data_dir,\n",
    "        all_schema=schema,\n",
    "        )\n",
    "\n",
    "        return data_validation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.TimeSeriesProject import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValiadtion:\n",
    "    def __init__(self, config: DataValidationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def RUL_calculator(self,df, df_max_cycles):\n",
    "        max_cycle = df_max_cycles[\"cycle\"]\n",
    "        result_frame = df.merge(max_cycle.to_frame(name='max_cycle'), left_on='id', right_index=True)\n",
    "        result_frame[\"RUL\"] = result_frame[\"max_cycle\"] - result_frame[\"cycle\"]\n",
    "        result_frame.drop(['max_cycle'], axis=1, inplace=True)\n",
    "        return result_frame\n",
    "\n",
    "\n",
    "    def validate_all_columns(self)-> bool:\n",
    "        try:\n",
    "            validation_status = None\n",
    "\n",
    "            data = pd.read_csv(self.config.unzip_data_dir,sep=\" \", header=None)\n",
    "            data.columns = [\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\"\n",
    "                    ,\"sensor6\",\"sensor7\",\"sensor8\",\"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\"\n",
    "                    ,\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "                    ,\"sensor20\",\"sensor21\",\"sensor22\",\"sensor23\"]\n",
    "            \n",
    "            data.drop(['sensor22', 'sensor23'], axis=1, inplace=True)\n",
    "            data.to_csv('artifacts/data_validation/output_data.csv', index=False)\n",
    "\n",
    "            jet_id_and_rul = data.groupby(['id'])[[\"id\" ,\"cycle\"]].max()\n",
    "            jet_id_and_rul.set_index('id', inplace=True)\n",
    "            jet_id_and_rul.to_csv('artifacts/data_validation/jet_id_and_rul.csv', index=False)\n",
    "\n",
    "\n",
    "            all_cols = list(data.columns)\n",
    "\n",
    "            all_schema = self.config.all_schema.keys()\n",
    "\n",
    "            for col in all_cols:\n",
    "                if col not in all_schema:\n",
    "                    validation_status = False\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\")\n",
    "                else:\n",
    "                    validation_status = True\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\")\n",
    "\n",
    "            data = self.RUL_calculator(data, jet_id_and_rul)\n",
    "            data.to_csv('artifacts/data_validation/relevent_data.csv', index=False)\n",
    "            \n",
    "\n",
    "            return validation_status\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_validation_config = config.get_data_validation_config()\n",
    "    data_validation = DataValiadtion(config=data_validation_config)\n",
    "    data_validation.validate_all_columns()\n",
    "    df = pd.read_csv('artifacts/data_validation/output_data.csv')\n",
    "    df_max_cycles = pd.read_csv('artifacts/data_validation/jet_id_and_rul.csv')\n",
    "    data_validation.RUL_calculator(df,df_max_cycles)\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
